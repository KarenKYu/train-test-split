{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source of Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll begin practice some of the techniques for building a simulation dataset.  \n",
    "\n",
    "The NYTimes is considering hiring us to predict the popularity of their articles.  We'd like to give them a sense of the predictions that we could make even before we get our hands on their data.  To do so we construct a sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a single feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a method called `build_feature` that returns a single feature vector.  The method takes an argument of `size`, which specifies the number of items in the feature vector.  The feature will be filled with numbers, so it also takes a second argument called `going_from` which specifies the range of integers in the  vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# use numpy's randint feature\n",
    "\n",
    "def build_feature(size = 50, going_from = [0, 100]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "word_counts = build_feature(50, [300, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.shape\n",
    "# (50, 1)\n",
    "# The feature word_counts should return a vector of rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[337],\n",
       "       [535],\n",
       "       [372]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[0:3]\n",
    "# array([[337],\n",
    "#        [535],\n",
    "#        [372]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great so now we have a vector that represents the number of words in a hypothetical collection of articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the targets variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that we are told that the true model, which determines the number of clicks on a news article, is the following: \n",
    "\n",
    "$y_{clicks} = \\theta_{word\\_counts}x_1 + \\theta_0$\n",
    "\n",
    "where:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $y$ is a vector that contains the actual clicks on each article\n",
    "* $x_1$ is a vector of word counts of each article and \n",
    "* $\\theta_0$ represents the baseline number of clicks that an article receives (regardless of the word count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also provided the following:\n",
    "\n",
    "* $\\theta_{word\\_counts} = 75$\n",
    "* $\\theta_0 = 10000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `word_counts` vector that we constructed above, and the defined parameter values, create our vector of target variables given the true model defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks\n",
    "# array([35275., 50125., 37900., 80875., 43300., 42175., 76225., 70600.,\n",
    "#        61750., 53575., 45850., 53200., 51550., 59275., 67600., 51400.,\n",
    "#        69250., 82600., 62350., 74650., 76000., 48625., 70225., 68350.,\n",
    "#        38950., 43075., 61975., 33025., 56425., 72550.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset, let's train our model on the constructed dataset.  Assign the model to the variable `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "model.coef_\n",
    "# array([   75.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.000000000007"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_\n",
    "# 10000.000000000007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring irreducible error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we now have trained a model to discover the true feature parameters of the underlying model.  Let's now consider, more realistically, that the underlying model takes the following form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = \\theta_1x_1 + \\theta_0 + \\epsilon_i$\n",
    "\n",
    "Where \n",
    "* $\\theta_1 = 75$\n",
    "* $\\theta_0 = 10000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use numpy's `randint` function to create a vector of random errors that range between positive and negative 8000.  Use this to create a new vector of errors called noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "noise = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -664, -5425, -1363,  5896,  3798,  6635, -5486, -6901,  6696,\n",
       "        3527])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise[0:10]\n",
    "# array([ -664, -5425, -1363,  5896,  3798,  6635, -5486, -6901,  6696,\n",
    "#         3527])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a target variable called`noisy_clicks` which is adds the `noise` defined above to our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_clicks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a20e4a450>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(word_counts.reshape(50), noisy_clicks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we already have a model that has discovered the parameters of our model:\n",
    "\n",
    "$y = \\theta_1x_1 + \\theta_0 + \\epsilon_i$\n",
    "\n",
    "Where \n",
    "* $\\theta_1 = 75$\n",
    "* $\\theta_0 = 10000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, that $\\epsilon_i$ represents our irreducible error, that is inherent to the future outcomes we try to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this.  Once again, these are the parameters of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.000000000007"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_\n",
    "# array([   75.])\n",
    "\n",
    "model.intercept_\n",
    "# 10000.000000000007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these parameters along with our features to predict our data.  Use the sklearn's `predict` function in the linear regression class to make the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35275., 50125., 37900., 80875., 43300., 42175., 76225., 70600.,\n",
       "       61750., 53575., 45850., 53200., 51550., 59275., 67600., 51400.,\n",
       "       69250., 82600., 62350., 74650., 76000., 48625., 70225., 68350.,\n",
       "       38950., 43075., 61975., 33025., 56425., 72550., 55975., 70975.,\n",
       "       56200., 48175., 52300., 81475., 79525., 64825., 79975., 66700.,\n",
       "       73150., 37825., 61525., 66550., 74575., 55975., 71125., 69775.,\n",
       "       35725., 76600.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = None\n",
    "predictions\n",
    "# array([35275., 50125., 37900., 80875., 43300., 42175., 76225., 70600.,\n",
    "#        61750., 53575., 45850., 53200., 51550., 59275., 67600., 51400.,\n",
    "#        69250., 82600., 62350., 74650., 76000., 48625., 70225., 68350.,\n",
    "#        38950., 43075., 61975., 33025., 56425., 72550., 55975., 70975.,\n",
    "#        56200., 48175., 52300., 81475., 79525., 64825., 79975., 66700.,\n",
    "#        73150., 37825., 61525., 66550., 74575., 55975., 71125., 69775.,\n",
    "#        35725., 76600.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's calculate the RSS of our model applied to predicting our `noisy_clicks`.\n",
    "\n",
    "> First calculate the errors at each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -664., -5425., -1363.,  5896.,  3798.,  6635., -5486., -6901.,\n",
       "        6696.,  3527., -3230., -7567., -1249.,  2827., -5227., -2833.,\n",
       "        3071.,  7647., -5222., -1452.,   316., -4300., -1051., -5273.,\n",
       "       -2685.,  5414., -1084., -2966.,  5163., -3853.,  6695.,  3814.,\n",
       "         170.,  7905., -4358., -3012., -7745.,  -509.,  1541., -2792.,\n",
       "       -4220.,  1518.,  -378., -6625.,  3475., -1735., -7969.,  2690.,\n",
       "       -4336., -6412.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = None\n",
    "errors\n",
    "\n",
    "# array([ -664., -5425., -1363.,  5896.,  3798.,  6635., -5486., -6901.,\n",
    "#         6696.,  3527., -3230., -7567., -1249.,  2827., -5227., -2833.,\n",
    "#         3071.,  7647., -5222., -1452.,   316., -4300., -1051., -5273.,\n",
    "#        -2685.,  5414., -1084., -2966.,  5163., -3853.,  6695.,  3814.,\n",
    "#          170.,  7905., -4358., -3012., -7745.,  -509.,  1541., -2792.,\n",
    "#        -4220.,  1518.,  -378., -6625.,  3475., -1735., -7969.,  2690.,\n",
    "#        -4336., -6412.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the rss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035560938.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss = None\n",
    "rss\n",
    "# 1035560938.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can calculate or mean squared error, simply by dividing the residual sum of squares by the number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20711218.76"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = None\n",
    "mse\n",
    "\n",
    "# 20711218.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we could have just used the sklearn library to calculate this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20711218.76"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import function from sklearn to calculase mse\n",
    "\n",
    "# 20711218.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you remember RSS, RSS squares the error and then adds up these errors.  So, with mean squared error, we now just take the average of RSS.  But it's still hard to interpret squared error.  A more understandable metric is the root mean squared error, which is just the square root of the average squared error.  We'll calculate it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4550.958004640342"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# 4550.958004640342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this says that on average, we are off by 4550 when we try to predict the noisy clicks.  This makes sense, as it's a bit larger thanthe average of our irreducible error, that we added with our `noise` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3934.4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(abs(noise))\n",
    "# 3934.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now produce a model that not only suffers from irreducible error, but also suffers from variance.  Use the `noisy_clicks` target variables and the previously defined `features` to produce this model.  Assign it to the variable `model_with_variance`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_variance =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72.88699818])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_with_variance.coef_\n",
    "# array([72.88699818])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10636.147158583459"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_variance.intercept_\n",
    "# 10636.147158583459"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So comparing with our first model, we see that our parameters no longer match the underlying values.  This is because we trained our model on a noisy dataset, which is what we'll see in real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two models - one with irreducible error, and another that suffers from irreducible error and variance.  Let's compare these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already calculated the root mean squared error for our first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a new vector of target variables to see how our original model and our model with variance performs.  To do so, we'll first generate a new set of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6711,  -707,  4815, -6656,  3633,  -709,  1372,  2201, -3171,\n",
       "       -6480,  2141,  2234,  1224,  1289, -1600,  6826,  4328,  2742,\n",
       "        7780,  6707, -2352, -3548, -7761, -5557, -5898, -4584,  3627,\n",
       "        -710, -7426,  7905,  5512,    36,  1166,  6001,  3318,  4365,\n",
       "        7813,  4301, -1101, -7591, -6594, -7347, -4068, -6634,  4062,\n",
       "        7006,   281, -5300,  -511,  6879])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "new_errors = np.random.randint(-8000, 8000, 50)\n",
    "new_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a new vector of observed data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28564, 49418, 42715])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_noisy_clicks = clicks + new_errors\n",
    "new_noisy_clicks[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the root mean squared error for both the original `model` and the `model_with_variance` on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4921.427288907152"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_new_noisy_clicks_original_model = None\n",
    "rmse_new_noisy_clicks_original_model\n",
    "# 4921.427288907152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5073.693321672944"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_new_noisy_clicks_variance_model = None\n",
    "rmse_new_noisy_clicks_variance_model\n",
    "# 5073.693321672944"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our model with variance did worse on this new set of target variables than it did with the data that it trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465.829626293661"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(mean_squared_error(noisy_clicks, model_with_variance.predict(word_counts)))\n",
    "# 4465.829626293661"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is generally the case.  When we train the data, our linear regression model is trying to fit to the training data.  And thus it finds parameters that match some of the randomness in the training data.  However, because this randomness is not replicated in future data, it generally performs less well on data it has not seen.  When seeing how well our model will perform, we want to see how well it performs on data it has not trained on, as this better simulates how the model will perform in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job!  We used this lesson to review our teachings in linear algebra and numpy.  We also used it to develop our understanding of types of error: both variance and irreducible error.  We saw that if we only assess how well a model performs on the training set, this performance likely will not generalize to future data as our model has likely overfit to the training set.  To remedy this, we should assess how well a model performs on data it has not trained on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
