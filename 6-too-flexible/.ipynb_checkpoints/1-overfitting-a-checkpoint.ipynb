{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have seen our three sources of error in a machine learning model: irreducible error, variance and bias.  We've seen that bias can be caused by underfitting our model.  Here, let's see how by overfitting our model our model is more subject to variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have stored our feature data in the `data.py` file.  Our data adheres to the following model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$customer\\_amount = 3*temp + 40*is\\_weekend + 10 + \\epsilon_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the error related to our model, when we properly fit a model with temperatures and weekends against our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.565735597602885"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import temps_and_is_weekends, customers_with_errors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(temps_and_is_weekends, customers_with_errors)\n",
    "\n",
    "sqrt(mean_squared_error(customers_with_errors, model.predict(temps_and_is_weekends)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That error is caused by randomness in our training data.  Here is our related plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import plot, trace_values, build_layout\n",
    "import numpy as np\n",
    "temps = np.array(temps_and_is_weekends)[:, 0]\n",
    "predictions = model.predict(temps_and_is_weekends)\n",
    "\n",
    "trace_1 = dict(x = temps, y =  customers_with_errors, mode = 'markers') \n",
    "model_trace = trace_values(temps, predictions, mode = 'lines', name = 'updated model')\n",
    "plot([trace_1, model_trace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model is pretty good, and has an rmse of  21.5.  Let's try to do better.  One way that we try to improve our model is by adding another another feature.  But it's difficult to know beforehand if a feature is can be used to explain our outcome.  So we may be adding something to our model that is completely irrelevant.  Let's see what happens when we add an irrelevant feature into our model.\n",
    "\n",
    "Our irrelevant feature is called `random_ages`, and it represents the average age of the cashiers who were working that day.  But really it's just a list of random data.  Because it's just a list of random data that we'll produce now, it would not have any relevance to our customer amounts list.  Still, let's throw it into our model and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 30, 30]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint, seed\n",
    "seed(2)\n",
    "random_ages = [randint(25, 65) for num in range(0, 50)] \n",
    "random_ages[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's add it to our list of independent variables and throw it into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import temps, random_ages, is_weekends\n",
    "updated_independent_vars = list(zip(temps, random_ages, is_weekends))\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "updated_model = LinearRegression()\n",
    "updated_model.fit(updated_independent_vars, customers_with_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.556603670493445"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "sqrt(mean_squared_error(customers_with_errors, updated_model.predict(updated_independent_vars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as you can see, by introducing the `random_ages`, our rmse did decrease - even if just a little bit.  It went from 21.56 to 21.55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have two different models, and the one that includes our random list of average ages has the higher score.  But it seems like it can't be right.  Remember, we just randomly generated our list of ages.  They obviously did not cause an impact on our previously formulated list of customer amounts.  So how do we account for the decrease in our error.\n",
    "\n",
    "The reason why training with our list of random numbers improved the model is another case of overfitting.  We are essentially including a noisy, irrelevant parameter in our model.  With this, our linear regression algorithm takes the numbers in this parameter and tries to find an association to the number of customers.  But this association, isn't really there.  It's just picking up on a coincidental association between the random numbers and the average customers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We named this error as variance.  As we see, introducing *more* parameters makes our model more flexible and thus introduces more variance.  \n",
    "\n",
    "This struggle to balance adding too many parameters and introducing error due to variance, or not including enough parameters and introducing error due to bias is called the bias variance tradeoff.  We'll continue to explore this, as well as a technique to help us strike the right balance - by again using a holdout set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we saw another source of error called variance.  Error due to variance occurs when our model is too flexible, and we include parameters that do not have predictive value.  Error due to variance can be deceptive because when we introduce variance the score on our training data improves.  However, this is due to our model fitting to randomness in the training data and not detecting an underlying association between our new independent variable and our dependent variable.\n",
    "\n",
    "We have now seen that error can occur from including too few parameters, which introduces bias, and from too many parameters, which introduces variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
