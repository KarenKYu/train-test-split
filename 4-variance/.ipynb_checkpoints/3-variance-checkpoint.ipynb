{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A little more complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we started with a machine learning algorithm that found the true relationship between customers and temperature beneath our data: \n",
    "\n",
    "$$customers = 3*temperature + 10$$\n",
    "\n",
    "Then we showed that even when our model finds this true relationship, it cannot perfectly predict data with random errors.  This is because our machine learning algorithm cannot predict random influences of future outcomes, which makes sense.  This is called *irreducible error*.\n",
    "\n",
    "Now we'll make things harder for our machine learning algorithm.  Unlike in the last lesson, we won't *train* our algorithm on a perfectly clean dataset.  In other words, this time our machine learning algorithm won't have the benefit of training on data that perfectly reflects the true underlying model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more realistic.  In real life, we don't train our model that perfectly matches a linear model.  The data we collect will be subject to a degree of randomness -- or in other words, noise.  In this lesson, we'll see the complications that arise from training on noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on a noisy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we have our customer model of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$customers = 3*temperature + 10 + \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We'll import a function, `build_dataset` that constructs a noisy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from data import build_data_set\n",
    "seed(4)\n",
    "\n",
    "dataset = build_data_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `dataset` is a numpy array of rows each with a feature of temperatures, and target variable of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = dataset[:, 0]\n",
    "noisy_customers = dataset[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~JeffKatzy/233'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graph import trace_values, plot\n",
    "import plotly.plotly as py\n",
    "data_trace = trace_values(temperatures, noisy_customers, name = 'initial data')\n",
    "layout = {'yaxis': {'title': 'customers'}, 'xaxis': {'title': 'temperature'}}\n",
    "py.plot([data_trace], layout = layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now it's time for us to train our model on this noisy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "initial_model = LinearRegression()\n",
    "initial_model.fit(temperatures.reshape(-1, 1), noisy_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at what the model discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.49140605])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.212252962233208"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now notice that when we train our data on the noisy data, our model came close to discovering the model of $y = 3x + 10$, but it was a little off.  Why *is* this?  Why did it not say that the best fit line has the underlying parameters of $y = 3x + 10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well here, our hypothesis function did not find the parameters of the true model because whenever we train our model, the model is simply trying to draw a line that minimizes the sum of the squared errors through the random data.  And so the ending hypothesis function is influenced by the whims and randomness it sees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://plot.ly/~JeffKatzy/235'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from graph import trace_values\n",
    "import plotly.plotly as py\n",
    "from data import temperatures, initial_model, noisy_customers\n",
    "sorted_temps = np.sort(temperatures)\n",
    "layout = {'yaxis': {'title': 'customers'}, 'xaxis': {'title': 'temperature'}}\n",
    "data_trace = trace_values(temperatures, noisy_customers, name = 'initial data')\n",
    "customer_predictions = initial_model.predict(sorted_temps.reshape(-1, 1))\n",
    "model_trace = trace_values(sorted_temps, customer_predictions, name = 'expected', mode = 'lines')\n",
    "py.plot([data_trace, model_trace], layout = layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.303665437086153"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(noisy_customers, initial_model.predict(temperatures.reshape(-1, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this says that when we make a prediction, on average we will be off by 25.  The root of this error is called variance.  Variance measures the amount of that our parameters change each time that we estimate the model.  And our parameters would change because the our models are trained on different subsets of our random data.  \n",
    "\n",
    "By way of example, let's train our model on four hundred different sets of data that have an element of randomness in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import build_data_set\n",
    "\n",
    "models = []\n",
    "for training_set in range(0, 600):\n",
    "    dataset = build_data_set()\n",
    "    model = LinearRegression()\n",
    "    temperatures = dataset[:, 0]\n",
    "    noisy_customers = dataset[:, 1]\n",
    "    \n",
    "    model.fit(temperatures.reshape(-1, 1), noisy_customers)\n",
    "    models.append(model)\n",
    "\n",
    "parameters = np.array([(model.coef_, model.intercept_) for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.01825515])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(parameters[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.661770692678378"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(parameters[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that our parameters are much closer to the underlying model than when we just performed one estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just saw the two main points with variance.  \n",
    "1. If we trained our model many times withÂ data that random variations, the parameters of our model would vary each time and this variation from the true parameter is called error due to variance.  \n",
    "2. However, if we were to perform fit our model many times, we expect each estimated parameter to hover around the true parameter and, for the average of each parameter to approach the parameter of the true model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned about error due to variance.  Error due to variance occurs because we train on data that has randomness built into it.  Because of this if we imagined (or actually did) train our model on different multiple times, the parameters of our model would vary each time.  This fluctuation is called variance.  Now because this variance is random, if we were to take the average of the parameters we would expect the error due to variance to cancel each other out, and thus equal zero.  We saw a demonstration of this, when we averaged our models, and the parameters approached the true model parameters.\n",
    "\n",
    "We saw that one danger of error due to variance is overfitting.  We have overfitting when our model performs better on data it trained on than on data it did not yet see.  This problem is referred to as a problem of generalization.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
